# ğŸ“Œ Projeto: Pipeline de Dados no Azure

## ğŸ“– DescriÃ§Ã£o
Este projeto implementa um **pipeline de dados no Azure**, com foco na ingestÃ£o, preparaÃ§Ã£o e transformaÃ§Ã£o de dados em um ambiente de **Data Engineering moderno**.  

Ele foi desenvolvido como parte de um **laboratÃ³rio prÃ¡tico da certificaÃ§Ã£o DP-203 (Azure Data Engineer Associate)**, utilizando os serviÃ§os do **Azure Synapse Analytics** e **Data Lake Storage**.

O objetivo Ã© demonstrar, de forma prÃ¡tica, como configurar fluxos de dados para carregar, transformar e disponibilizar informaÃ§Ãµes de forma escalÃ¡vel, segura e integrada.

O pipeline realiza a comparaÃ§Ã£o de um registro especÃ­fico com uma base de dados maior para identificar se ele jÃ¡ existe.
- Fontes de dados: importa informaÃ§Ãµes de duas origens â€” uma tabela no Data Warehouse e um arquivo CSV.
- Coleta e transformaÃ§Ã£o: os dados sÃ£o unificados e passam por uma etapa de transformaÃ§Ã£o, onde o registro da tabela do Data Warehouse Ã© comparado com os registros do arquivo CSV.
- ValidaÃ§Ã£o: nessa etapa, Ã© verificado se o registro jÃ¡ estÃ¡ presente na base maior.
- ExportaÃ§Ã£o: o resultado final Ã© gravado em uma tabela externa para consulta e uso posterior.

---

## âš™ï¸ Tecnologias Utilizadas
- **Azure Synapse Analytics** â†’ CriaÃ§Ã£o e orquestraÃ§Ã£o do pipeline de dados  
- **Azure Data Lake Storage** â†’ Armazenamento dos arquivos de entrada e dados preparados  
- **PowerShell** â†’ AutomaÃ§Ã£o de setup inicial  
- **Git** â†’ Versionamento e gerenciamento do repositÃ³rio  
- **SQL** â†’ TransformaÃ§Ã£o e manipulaÃ§Ã£o de dados dentro do Synapse  

---

## ğŸš€ Etapas Implementadas

### ğŸ”¹ 1. ConfiguraÃ§Ã£o do Ambiente
- Clonagem do repositÃ³rio oficial de laboratÃ³rios **DP-203**  
- ExecuÃ§Ã£o de scripts de setup (`setup.ps1`) para provisionar os recursos necessÃ¡rios  

### ğŸ”¹ 2. CriaÃ§Ã£o do Pipeline no Synapse
- Desenvolvimento do fluxo de dados **LoadProducts**  
- DefiniÃ§Ã£o de **serviÃ§os vinculados (Linked Services)** para integraÃ§Ã£o segura com o Data Lake  
- ConfiguraÃ§Ã£o de pastas de preparo no storage:  
  - `container = files`  
  - `diretÃ³rio = stage_products`  

### ğŸ”¹ 3. TransformaÃ§Ã£o de Dados
- DefiniÃ§Ã£o de mapeamento entre origem (arquivos no Data Lake) e destino (tabelas no Synapse)  
- AplicaÃ§Ã£o de regras de transformaÃ§Ã£o e limpeza  

### ğŸ”¹ 4. ExecuÃ§Ã£o e ValidaÃ§Ã£o
- Rodagem do pipeline para ingestÃ£o dos dados  
- ValidaÃ§Ã£o por meio de **consultas SQL** no Synapse  
- Armazenamento dos resultados prontos para anÃ¡lises posteriores  

---

## ğŸ“Š BenefÃ­cios do Projeto
âœ”ï¸ Demonstra boas prÃ¡ticas de **Data Engineering em nuvem**  
âœ”ï¸ Integra diferentes serviÃ§os do Azure em um fluxo orquestrado  
âœ”ï¸ Facilita a compreensÃ£o de pipelines de dados escalÃ¡veis  
âœ”ï¸ Serve como base de estudo para certificaÃ§Ãµes como **DP-203**  

---

## ğŸ“¸ Exemplos
O projeto inclui capturas de tela que ilustram:
- A configuraÃ§Ã£o do fluxo de dados  
- A execuÃ§Ã£o e monitoramento do pipeline no Synapse  
- Os resultados carregados no ambiente de anÃ¡lise  
